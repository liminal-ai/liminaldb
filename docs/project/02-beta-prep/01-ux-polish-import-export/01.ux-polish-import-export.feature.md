# Feature: UX Polish & Import/Export

This feature spec defines the user-facing polish and data portability capabilities for the Beta Prep milestone. It covers theming, prompt import/export, and OpenAI widget integration, plus iterative refinement work that falls outside formal TDD cycles.

**Audience:** Development agents, tech design authors, reviewers

**Parent PRD:** [Beta Prep PRD](../beta-prep.prd.md)

**Contents:**
- **Flows 1-4:** Theme Selection, Import Prompts, Export Prompts, OpenAI PIP Integration
- **Iterative Refinement:** Non-TDD work for validation, polish, and integration

---

## Profile

**Persona:** Early adopter preparing to use LiminalDB for real work

**Current pain:** The product works but feels unpolished. There's only a dark theme. Users can't bring in their existing prompts from other sources. There's no way to export prompts for backup or migration. Search and data entry haven't been validated with realistic usage patterns.

**What they can do after this feature:**
- Choose from multiple themes including light and dark
- Import prompts from JSON files (individually or in batch)
- Export prompts for backup or portability
- Encounter fewer rough edges in search and data entry flows
- Access prompts via ChatGPT using PIP form

---

## Scope

### In Scope

- Multiple theme options with light and dark variants
- Theme selector in UI with persistence across sessions
- Batch import from JSON with validation and error handling (web UI + MCP)
- Batch export to JSON (web UI + MCP)
- Single prompt export
- Duplicate handling on import
- OpenAI PIP integration (web app in ChatGPT PIP form)
- Iterative validation and polish of existing flows
- Refactoring and integration into application patterns

### Out of Scope

- Custom user-defined themes
- CSV import/export format
- Import from other prompt management tools (custom adapters)
- Automatic sync with external systems
- Import/export of drafts
- Import/export of usage statistics or metadata (created date, last used, etc.)

---

## Assumptions

| ID | Assumption | Status | Notes |
|----|------------|--------|-------|
| A1 | Theme designs exist or will be provided | Resolved | Ship tokyo-night, teal, + 2 light themes |
| A2 | Import preview can use existing prompt list patterns | Assumed | May need discovery |
| A3 | Web app shell/portlet works in PIP viewport | Needs validation | May need adjustments for Flow 4 |

---

## User Flows & Acceptance Criteria

### Flow 1: Theme Selection

**Before:** App has only dark theme. No user preference.

**After:** User chooses from several theme options. Choice persists across sessions.

**Flow:**
1. User clicks theme selector in application header
2. Dropdown shows available themes
3. User selects a theme
4. UI immediately updates to selected theme
5. User closes browser
6. User returns later - selected theme still active

**Theme options (4 themes for beta):**
- tokyo-night (dark)
- teal (dark)
- Light theme 1 (TBD)
- Light theme 2 (TBD)

**Acceptance Criteria:**

| ID | Criteria |
|----|----------|
| AC-1 | Theme selector is accessible from application header |
| AC-2 | Four themes available: tokyo-night, teal, and 2 light themes |
| AC-3 | Selecting a theme immediately updates the UI |
| AC-4 | Selected theme persists across browser sessions (localStorage) |
| AC-5 | Theme changes apply to all UI components consistently (header, sidebar, content, modals) |
| AC-6 | Each theme appears intentional and polished (see note below) |

**Note on AC-6:** This criterion ensures themes look designed rather than auto-generated or broken (e.g., inverted colors, unreadable text, inconsistent contrast). It cannot be verified by automated test - it requires visual design review before the theme is shipped. This is important because a broken theme undermines user trust and makes the product feel unfinished. Verification: design review sign-off.

**Test Conditions:**

| TC | Condition | ACs |
|----|-----------|-----|
| TC-1 | Given UI loaded, when user clicks theme selector in header, then theme dropdown displayed | AC-1 |
| TC-2 | Given theme dropdown open, then 4 theme options visible (tokyo-night, teal, 2 light) | AC-2 |
| TC-3 | Given theme dropdown open, when user selects tokyo-night, then UI updates to tokyo-night | AC-3 |
| TC-4 | Given theme dropdown open, when user selects a light theme, then UI updates to light theme | AC-3 |
| TC-5 | Given theme dropdown open, when user selects teal, then UI updates to teal | AC-3 |
| TC-6 | Given user selected light theme, when browser closed and reopened, then light theme still active | AC-4 |
| TC-7 | Given theme applied, then header uses theme colors | AC-5 |
| TC-8 | Given theme applied, then sidebar uses theme colors | AC-5 |
| TC-9 | Given theme applied, then content area uses theme colors | AC-5 |
| TC-10 | Given theme applied, when modal opened, then modal uses theme colors | AC-5 |

---

### Flow 2: Import Prompts

**Before:** User must create each prompt manually. No way to bring in existing prompts.

**After:** User uploads a JSON file and imports prompts in batch.

**UI Location:** Import button in prompt list header/toolbar area, alongside existing controls.

**Flow:**
1. User clicks Import button in prompt list
2. File picker opens
3. User selects JSON file
4. System validates file format and structure
5. Preview shows prompts to be imported with any issues flagged
6. User can deselect prompts or handle duplicates
7. User confirms import
8. Prompts added to library
9. Success summary shows results

**Variations:**
- Invalid JSON shows parse error with line/position if available
- Prompts with validation errors (missing required fields) flagged in preview
- User can deselect individual prompts before confirming
- Duplicate slugs trigger duplicate handling options
- File over size limit rejected with clear message
- Empty file (valid JSON but no prompts) shows appropriate message

**Duplicate handling flow:**
1. System detects slug collision during preview
2. User presented with options: Skip, Rename (auto-suffix), or Overwrite
3. User can select handling per duplicate or "apply to all"
4. Import proceeds with selected handling

**Partial failure handling:**
If some prompts succeed and others fail during import, successfully imported prompts are kept. User sees summary showing which succeeded and which failed with reasons.

**Import format (matches export format):**
```json
{
  "version": "1.0",
  "prompts": [
    {
      "slug": "my-prompt",
      "name": "My Prompt",
      "description": "A helpful prompt",
      "content": "The prompt content...",
      "tags": ["tag1", "tag2"]
    }
  ]
}
```

**Acceptance Criteria:**

| ID | Criteria |
|----|----------|
| AC-7 | Import button is visible in prompt list toolbar |
| AC-8 | Clicking Import opens file picker filtered to JSON files |
| AC-9 | Valid JSON file with prompts array is accepted |
| AC-10 | Invalid JSON displays clear parse error with position if available |
| AC-11 | Valid JSON missing required prompt fields shows validation errors in preview |
| AC-12 | Preview shows list of prompts to be imported before committing |
| AC-13 | Prompts with validation errors are visually flagged in preview |
| AC-14 | User can deselect individual prompts from import |
| AC-15 | Valid prompts are added to user's library on confirm |
| AC-16 | Success message shows count of imported prompts |
| AC-17 | Duplicate slugs are detected and flagged in preview |
| AC-18 | User can choose to skip duplicates |
| AC-19 | User can choose to auto-rename duplicates (suffix added) |
| AC-20 | User can choose to overwrite duplicates |
| AC-21 | User can apply duplicate handling choice to all duplicates |
| AC-22 | Import preserves all prompt fields (name, slug, description, content, tags) |
| AC-23 | Imported prompts appear in prompt list immediately |
| AC-24 | Files exceeding size limit are rejected with clear message |
| AC-25 | Partial failures show summary of successes and failures with reasons |
| AC-26 | User can cancel import from preview before confirming |
| AC-27 | Empty prompts array shows "No prompts to import" message |

**MCP Parity:**

| ID | Criteria |
|----|----------|
| AC-44 | MCP tool `import_prompts` accepts JSON content and imports prompts |
| AC-45 | MCP import validates prompt structure and returns validation errors |
| AC-46 | MCP import supports duplicate handling options (skip, rename, overwrite) |
| AC-47 | MCP import returns summary of imported prompts and any failures |

**Note on MCP import:** The model passes JSON content to the tool (not a file path). This is consistent with MCP patterns where content flows through the model. Users might paste JSON or have the model construct it from conversation.

**Test Conditions:**

File selection and validation:
- **TC-11:** Given prompt list displayed, then Import button visible in toolbar *(AC-7)*
- **TC-12:** Given Import clicked, then file picker opens filtered to .json files *(AC-8)*
- **TC-13:** Given valid JSON with prompts array selected, then preview displayed *(AC-9, AC-12)*
- **TC-14:** Given malformed JSON file, when selected, then parse error displayed with line/position *(AC-10)*
- **TC-15:** Given JSON with prompt missing content field, then validation error shown in preview *(AC-11, AC-13)*
- **TC-16:** Given file over size limit, when selected, then rejection message displayed *(AC-24)*
- **TC-17:** Given valid JSON with empty prompts array, then "No prompts to import" message shown *(AC-27)*

Preview and selection:
- **TC-18:** Given valid JSON with 5 prompts, then preview shows 5 prompts *(AC-12)*
- **TC-19:** Given preview shown, when user deselects 2 prompts and confirms, then 3 prompts imported *(AC-14)*
- **TC-20:** Given preview shown, when user clicks Cancel, then no prompts imported *(AC-26)*

Import execution:
- **TC-21:** Given valid prompts confirmed, then prompts added to library *(AC-15)*
- **TC-22:** Given 5 prompts imported successfully, then message shows "5 prompts imported" *(AC-16)*
- **TC-23:** Given prompt with tags in JSON, when imported, then tags preserved *(AC-22)*
- **TC-24:** Given prompts imported, then appear in prompt list without page refresh *(AC-23)*

Duplicate handling:
- **TC-25:** Given import with slug matching existing prompt, then duplicate flagged in preview *(AC-17)*
- **TC-26:** Given duplicate, when user selects Skip, then existing prompt unchanged and new not added *(AC-18)*
- **TC-27:** Given duplicate "my-prompt", when user selects Rename, then imported as "my-prompt-1" *(AC-19)*
- **TC-28:** Given duplicate, when user selects Overwrite, then existing prompt replaced with imported version *(AC-20)*
- **TC-29:** Given 3 duplicates, when user selects "Apply to all: Skip", then all 3 duplicates skipped *(AC-21)*

Partial failure:
- **TC-30:** Given 5 prompts where 2 have validation errors, when import confirmed, then 3 imported and summary shows 2 failures with reasons *(AC-25)*

MCP import:
- **TC-42:** Given MCP client, when `import_prompts` called with valid JSON, then prompts imported *(AC-44)*
- **TC-43:** Given MCP client, when `import_prompts` called with invalid prompt (missing content), then validation error returned *(AC-45)*
- **TC-44:** Given MCP client, when `import_prompts` called with duplicate_handling: "skip", then duplicates skipped *(AC-46)*
- **TC-45:** Given MCP client, when `import_prompts` completes, then summary returned with count and any failures *(AC-47)*

---

### Flow 3: Export Prompts

**Before:** No way to get prompts out of the system. Data feels trapped.

**After:** User can export all prompts or individual prompts as JSON.

**UI Location:**
- Export All: Button in prompt list toolbar
- Export Single: Action in prompt viewer/editor

**Flow - Export all:**
1. User clicks Export button in prompt list toolbar
2. System generates JSON file with all user's prompts
3. Browser downloads file with date-stamped filename

**Flow - Export single:**
1. User views a prompt
2. User clicks Export action (menu or button)
3. Browser downloads JSON file with that single prompt

**Export format:**
```json
{
  "version": "1.0",
  "exportedAt": "2025-01-10T12:34:56Z",
  "prompts": [
    {
      "slug": "my-prompt",
      "name": "My Prompt",
      "description": "A helpful prompt",
      "content": "The prompt content...",
      "tags": ["tag1", "tag2"]
    }
  ]
}
```

**Format notes:**
- `tags` is always an array, empty `[]` if prompt has no tags
- Only editable fields exported (no usage stats, created date, etc.)
- Same format for single and batch export
- `version` enables future format evolution

**Acceptance Criteria:**

| ID | Criteria |
|----|----------|
| AC-28 | Export All button is visible in prompt list toolbar |
| AC-29 | User can export a single prompt from prompt view |
| AC-30 | Export produces valid, parseable JSON file |
| AC-31 | Export includes version identifier |
| AC-32 | Export includes exportedAt timestamp |
| AC-33 | Export includes all prompt fields (slug, name, description, content, tags) |
| AC-34 | Prompts with no tags export with empty tags array `[]` |
| AC-35 | Exported file can be re-imported successfully (round-trip) |
| AC-36 | Export filename includes date for identification |
| AC-37 | Export All with zero prompts shows appropriate message (no empty file download) |

**MCP Parity:**

| ID | Criteria |
|----|----------|
| AC-48 | MCP tool `export_prompts` returns all user's prompts as JSON |
| AC-49 | MCP tool `export_prompt` accepts slug and returns single prompt as JSON |
| AC-50 | MCP export returns same format as web export (version, timestamp, prompts array) |

**Note on MCP export:** Returns JSON content directly to the model/user. The model or user can then save it, share it, or process it further.

**Test Conditions:**

- **TC-31:** Given prompt list displayed, then Export button visible in toolbar *(AC-28)*
- **TC-32:** Given user viewing a prompt, then Export action available *(AC-29)*
- **TC-33:** Given user with prompts, when Export All clicked, then valid JSON file downloaded *(AC-28, AC-30)*
- **TC-34:** Given user viewing prompt, when Export clicked, then JSON file with 1 prompt downloaded *(AC-29, AC-30)*
- **TC-35:** Given exported file, then contains "version" field with value "1.0" *(AC-31)*
- **TC-36:** Given exported file, then contains "exportedAt" with valid ISO timestamp *(AC-32)*
- **TC-37:** Given prompt with name, slug, description, content, tags, when exported, then all fields present in JSON *(AC-33)*
- **TC-38:** Given prompt with no tags, when exported, then tags field is empty array `[]` *(AC-34)*
- **TC-39:** Given file exported, when same file imported, then prompts restored with identical field values *(AC-35)*
- **TC-40:** Given export on 2025-01-10, then downloaded filename contains "2025-01-10" *(AC-36)*
- **TC-41:** Given user with zero prompts, when Export All clicked, then message shown instead of empty file download *(AC-37)*

MCP export:
- **TC-46:** Given MCP client, when `export_prompts` called, then JSON with all prompts returned *(AC-48)*
- **TC-47:** Given MCP client, when `export_prompt` called with slug "my-prompt", then JSON with that prompt returned *(AC-49)*
- **TC-48:** Given MCP export, then JSON contains version, exportedAt, and prompts array *(AC-50)*

---

### Flow 4: OpenAI PIP Integration

**Before:** LiminalDB web UI only accessible via browser. ChatGPT users must switch context.

**After:** LiminalDB web UI available as a PIP (picture-in-picture) form within ChatGPT, loaded via MCP tool call.

**Approach:** This is not a native OpenAI SDK widget. It's the existing web app loaded in a PIP form triggered by an MCP tool. The UI is the same web app - we're just making it work in the PIP context.

**Flow:**
1. User has LiminalDB MCP configured in ChatGPT
2. User asks to open LiminalDB or model decides to show it
3. MCP tool call loads web app in PIP form
4. User interacts with familiar web UI
5. User browses, searches, selects prompts
6. Selected prompt available for use in chat

**Technical considerations (for tech design):**
- Shell/portlet may need adjustments for PIP viewport
- Authentication: OpenAI handles auth in PIP context
- Selection return: MCP tool call (exact mechanism - model or widget initiated - decided in tech design)

**Acceptance Criteria:**

| ID | Criteria |
|----|----------|
| AC-38 | MCP tool can trigger PIP form with LiminalDB web UI |
| AC-39 | Web UI loads in PIP context (OpenAI handles auth) |
| AC-40 | User can browse prompts in PIP |
| AC-41 | User can search prompts in PIP |
| AC-42 | User can select a prompt and use it in chat |
| AC-43 | UI is usable within PIP viewport constraints |

**Test Conditions:**

- **TC-49:** Given ChatGPT with LiminalDB MCP, when tool triggers PIP, then web UI loads *(AC-38)*
- **TC-50:** Given PIP opened, then user's prompts are displayed *(AC-39, AC-40)*
- **TC-51:** Given PIP open, when user searches, then results filter *(AC-41)*
- **TC-52:** Given prompt selected in PIP, then content available for chat *(AC-42)*
- **TC-53:** Given PIP rendered, then all controls visible and usable *(AC-43)*

---

## Iterative Refinement

> **Note:** This section describes work that falls outside the formal TDD cycle. It captures validation, polish, and integration work that happens iteratively during and after the main feature implementation.

### Part A: Validation & Polish

Iterative improvements discovered through testing with realistic data and usage patterns. This work generates ad-hoc stories as issues are discovered.

**Activities:**
- Load realistic test data (varied prompt lengths, many tags, usage patterns)
- Test search with queries a real user would try
- Validate ranking surfaces the right prompts for typical queries
- Test data entry edge cases (very long content, special characters, unicode, emoji)
- Verify error messages are clear, specific, and actionable
- Test performance with larger prompt libraries
- Visual review of themes across all UI states
- Cross-browser testing of new functionality
- Accessibility review of new UI elements

**Success criteria:**
- Search returns relevant prompts for typical user queries
- Data entry validation errors display clear, actionable messages
- Edge cases handled gracefully without crashes or data loss
- Performance remains responsive with larger libraries
- Themes look polished across all components and states
- No regressions in existing functionality

**Deliverable:** Issues found during validation become bug tickets or polish stories. Each is implemented and verified. Stories may not follow full TDD cycle if they're small fixes.

### Part B: Refactoring & Integration

After rapid feature development, ensure new code is properly integrated into application patterns and maintainable long-term.

**Activities:**
- Review new code against established patterns (services, models, UI components)
- Ensure consistent error handling patterns
- Add missing test coverage for edge cases discovered in Part A
- Refactor any expedient code written during rapid iteration
- Update or add integration tests
- Ensure new features work correctly with existing features (search, ranking, drafts)
- Documentation updates (code comments, API docs if applicable)
- Verify CI/CD pipeline handles new functionality

**Success criteria:**
- New code follows established patterns documented in tech-arch
- Test coverage adequate for new functionality
- No tech debt items deferred without tracking
- Features integrate cleanly with existing functionality
- Build and test pipeline passes reliably

**Deliverable:** Refactoring PRs, test additions, documentation updates. May be bundled into a "hardening" story or tracked as individual items.

---

## Non-Functional Requirements

> **Note:** Performance targets below should be validated during implementation and adjusted if technical constraints require.

### Import Performance

Import should handle reasonable file sizes without timeout or browser hang.

**Requirements:**
- Import of 100 prompts completes within 5 seconds
- Progress indicator shown for imports taking over 1 second
- Browser remains responsive during import (no freezing)
- Maximum file size: 1MB

### Export Reliability

Export must not lose data or produce corrupt files.

**Requirements:**
- Export produces valid, parseable JSON
- All prompt data round-trips through export/import without loss or mutation
- Export handles libraries of any size (no artificial limit)

### Theme Consistency

Theme changes should be complete and immediate.

**Requirements:**
- No flash of wrong theme on page load (theme applied before first render)
- All UI components respond to theme (no orphan styles or unstyled elements)
- Theme persists across all routes and page navigations

---

## Architectural Overview

### Theme Implementation

Themes implemented via CSS custom properties (variables) for colors and styling. Theme selection persisted to localStorage. On page load, theme is read from localStorage and applied before first render to prevent flash of wrong theme. All UI components reference CSS variables rather than hardcoded colors.

### Import/Export Format

JSON schema for prompt interchange. Version field enables future format evolution without breaking existing exports. Same format used for import and export ensures round-trip compatibility. Import validates structure and field requirements before presenting preview.

### OpenAI PIP Integration

The existing web app loads in a PIP form via MCP tool call. No separate widget build - same web app, different viewport context. Shell/portlet architecture may need adjustments to work within PIP constraints. OpenAI handles authentication. Selected prompt returns to chat via MCP tool call.

---

## Dependencies

**Existing (complete):**
- Prompt CRUD and search functionality
- UI shell and component patterns
- Authentication and user context

**Required for this feature:**
- Convex mutations for batch import
- API endpoint for import (if not direct Convex)
- 2 light theme CSS files (tokyo-night and teal exist)
- PIP viewport testing in ChatGPT (for Flow 4)

---

## Related Work

- **Beta Prep PRD:** Parent document defining milestone and feature set
- **Feature 2: Infrastructure & E2E Testing:** Parallel feature in same PRD
- **Search & Select Feature:** Existing feature this builds upon (search, ranking, drafts patterns)
